\documentclass{article}

\usepackage{../zwliew}

\title{CS5234 - Algorithms at Scale}
\author{Liew Zhao Wei}
\date{Semester 1, 2023-2024}

\begin{document}
\maketitle
\hrule

\section{Probability and Bounds}

\begin{lemma}[Union Bound]
  For a countable set of events $A_1, A_2, \ldots$, we have
  \begin{align}
    \Pr\left[\bigcup_{i=1}^\infty A_i\right] \le \sum_{i=1}^\infty \Pr[A_i]
  \end{align}
\end{lemma}

\begin{lemma}[Linearity of Expectation]
  For any random variables $X_1, X_2, \ldots, X_n$, we have
  \begin{align}
    \Exp\left[\sum_{i=1}^n X_i\right] = \sum_{i=1}^n \Exp[X_i]
  \end{align}
\end{lemma}

\begin{lemma}[Markov's Inequality]
  For any \emph{non-negative} random variable $X$ and $t > 0$, we have
  \begin{align}
    \Pr[X \ge t] \le \frac{\Exp[X]}{t}
  \end{align}
\end{lemma}

\begin{lemma}[Chebyshev's Inequality]
  For any random variable $X$ with mean $\mu$ and variance $\sigma^2$, we have
  \begin{align}
    \Pr[|X - \mu| \ge t] \le \frac{\sigma^2}{t^2}
  \end{align}
  In fact, this holds for any moment $p$ instead of $2$.
\end{lemma}

\begin{lemma}[Chernoff-Hoeffding Bounds]
  Suppose $X_1, \ldots, X_n$ are \emph{independent} random variables with $X_i \in [0, 1]$.
  Let $X = \sum_{i=1}^n X_i$ and $\mu = \Exp[X]$ such that $\mu_L \leq \mu \leq \mu_H$.
  Then, for any $0 \leq \delta \leq 1$,
  \begin{align}
    \Pr[X \geq (1 + \delta)\mu] \le \exp{-\frac{\delta^2\mu}{3}}
    \\
    \Pr[X \leq (1 - \delta)\mu] \le \exp{-\frac{\delta^2\mu}{2}}
    \\
    \Pr \left[ |X - \mu| \geq \delta \mu \right] \le 2 \exp{-\frac{\delta^2\mu}{3}}
    \\
  \end{align}
  For any $\delta \geq 0$,
  \begin{align}
    \Pr[X \geq \mu + \delta] \le \exp{-\frac{2\delta^2}{n}}
    \\
    \Pr[X \leq \mu - \delta] \le \exp{-\frac{2\delta^2}{n}}
    \\
    \Pr \left[ |X - \mu| \geq \delta \right] \le 2 \exp{-\frac{2\delta^2}{n}}
  \end{align}
  More generally, if $a_i \leq X_i \leq b_i$, then
  \begin{align}
    \Pr[X \geq \mu + \delta] \le \exp{-\frac{2\delta^2}{\sum_{i=1}^n (b_i - a_i)^2}}
    \\
    \Pr[X \leq \mu - \delta] \le \exp{-\frac{2\delta^2}{\sum_{i=1}^n (b_i - a_i)^2}}
  \end{align}
\end{lemma}

WIP.

3. k-universal hash family (include space analysis)

\section{Simple Techniques}

WIP.
1. Reservoir sampling
2. Mean trick to drive down variance
3. Median trick to boost success Probability
4. Median of mean trick (2 and 3) to bound concetration

\section{Sketches}

1. combining sketches, linear sketches
2. Misra-Gries
3. Count-Min-Sketch and Count-Sketch

\section{Dimensions and Distances}

\begin{lemma}[Johnson-Lindenstrauss Lemma]
For any set $S \subseteq \reals^d$ of $n$-points, there is an embedding $f \colon \reals^d \to \reals^m$ for $m = O(\epsilon^{-2} \log n)$ such that
\begin{align}
  \forall u, v \in S \quad (1 - \epsilon) \|u - v\|_2^2 \le \|f(u) - f(v)\|_2^2 \le (1 + \epsilon) \|u - v\|_2^2
\end{align}
\end{lemma}
In other words, we can embed $S$ into a lower-dimensional space while approximately preserving $\ell_2$ norms.

Some observations:
\begin{itemize}
  \item The embedding has only a logarithmic dependence on $n$ and \emph{no} dependence on $d$.
  \item The embedding is can be generated using a Gaussian distribution.
  \item The embedding can be represented as a linear transformation, or in other words, a matrix.
\end{itemize}

\begin{definition}[Locality Sensitive Hash]
  A hash family $\mathcal{H} = \set{h \colon \mathcal{U} \to S}$ is a $(r_1, r_2, p_1, p_2)$-locally sensitive if for all points $p, p' \in \mathcal{U}$,

  \begin{enumerate}
    \item if $d(p, p') \le r_1$, then $\Pr_{h \in \mathcal{H}}[h(p) = h(p')] \ge p_1$,
    \item if $d(p, p') > r_2$, then $\Pr_{h \in \mathcal{H}}[h(p) = h(p')] \le p_2$.
  \end{enumerate}

\end{definition}
In other words, a \emph{locality sensitive hash} (LSH) is a hash family where similar items are more likely to collide.
Note that the definition makes sense only if $r_1 < r_2$ and $p_1 > p_2$.

WIP.
1. ANN, PLEB, how to solve them

\end{document}
