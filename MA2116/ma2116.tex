\documentclass{article}

\usepackage{../zwliew}

\title{MA2116 - Probability}
\author{Liew Zhao Wei}
\date{Semester 1, 2023-2024}

\begin{document}
\maketitle

\begin{abstract}
  This is a set of incomplete notes for an introductory course on probability.
\end{abstract}

\hrule

\section{Preliminaries}

\subsection{Taylor series expansions}

We should know the following Taylor series expansions by heart:
\begin{align*}
  e^x        & = \sum\limits_{n = 0}^\infty \frac{x^n}{n!}
  \\
  \ln(1 + x) & = \sum\limits_{n = 1}^\infty (-1)^{n + 1} \frac{x^n}{n}
  \\
  \sin x     & = \sum\limits_{n = 0}^\infty (-1)^n \frac{x^{2n + 1}}{(2n + 1)!}
  \\
  \cos x     & = \sum\limits_{n = 0}^\infty (-1)^n \frac{x^{2n}}{(2n)!}
\end{align*}

\subsection{Combinatorics}

Here are some useful combinatorial identities.

\[
  \text{Binomial theorem: } (x + y)^n = \sum\limits_{k = 0}^n \binom{n}{k} x^k y^{n - k}
\]

\[
  i \binom{n}{i} = n \binom{n - 1}{i - 1}
\]

\section{Axioms of Probability}

TODO.

\section{Discrete random variables}

\subsection{Expectation}

When given a random variable, we are often interested in its \emph{average} value.
This is captured by the notion of \emph{expectation}.

\begin{definition}[Expected value of a discrete r.v.]
  Let $X$ be a discrete random variable.
  Then the \emph{expected value}, or \emph{expectation}, of $X$, denoted by $\Exp[X]$, is defined as
  \[
    \Exp[X] = \sum_{x \in \Omega_X} x \Pr(X = x).
  \]
\end{definition}

\begin{proposition}[Expectation of a function of a discrete r.v.]
  Let $X$ be a discrete random variable and $g$ be real-valued a function.
  Then
  \[
    \Exp[g(X)] = \sum_{x \in \Omega_X} g(x) \Pr(X = x).
  \]
\end{proposition}

\begin{corollary}
  Let $X$ be a random variable and $a, b \in \reals$.
  Then
  \[
    \Exp[a X + b] = a \Exp[X] + b.
  \]
\end{corollary}

One important property of expectations of (general) random variables is that it is \emph{linear}.

\begin{theorem}{Linearity of expectation}
  Let $X_1, X_2, \ldots, X_n$ be random variables (not necessarily discrete).
  Then
  \[
    \Exp\left[\sum\limits_{i = 1}^n X_i\right] = \sum\limits_{i = 1}^n \Exp[X_i].
  \]
\end{theorem}

\subsection{Variance}

Expectation alone doesn't reveal much about the distribution of a random variable.
For example, compare these two slot machines:
\begin{enumerate}
  \item The first slot machine gives you \$100 with probability $1$.
  \item The second slot machine gives you \$10000 with probability $0.01$ and \$0 with probability $0.99$.
\end{enumerate}
The expected payout of both slot machines is \$100, but the chances of winning are very different.
This difference is captured by the notion of \emph{variance}.

\begin{definition}[Variance of a discrete r.v.]
  Let $X$ be a discrete random variable.
  Then the \emph{variance} of $X$, denoted by $\Var(X)$, is defined as
  \[
    \Var(X) = \Exp[(X - \Exp[X])^2].
  \]
\end{definition}

\begin{remark}[Alternative formula]
  The variance can also be computed using the following formula:
  \[
    \Var(X) = \Exp[X^2] - \Exp[X]^2.
  \]
\end{remark}

\begin{remark}
  Since variance is non-negative, we have
  \[
    \Exp[X^2] \geq \Exp[X]^2.
  \]
  This can be used to prove the \emph{friendship paradox}.
\end{remark}

\begin{proposition}[Variance of linear combination]
  Let $X$ be a discrete random variable and $a, b \in \reals$.
  Then
  \[
    \Var(a X + b) = a^2 \Var(X).
  \]
\end{proposition}

\subsection{Bernoulli and binomial random variables}

Perhaps the most basic and well-known random variable is the \emph{binomial} random variable and its little brother, the \emph{Bernoulli} random variable.
We motivate this with the age old example of a coin toss.

\begin{example}[Coin toss]
  Suppose we toss a coin $n$ times that comes up heads with probability $p$ and tails with probability $1 - p$.
  Let $X$ be the number of heads that appear.
  Then $X$ is a \emph{binomial} random variable with parameters $n$ and $p$.
  It takes values in $\{0, 1, \ldots, n\}$.
\end{example}

\begin{definition}[Binomial random variable]
  A random variable $X$ is said to be \emph{binomial} with parameters $n$ and $p$, denoted by $X \sim \Bin(n, p)$, if $X$ has the following probability mass function:
  \[
    \Pr(X = i) = \binom{n}{i} p^i (1 - p)^{n - i}, \quad i = 0, 1, \ldots, n.
  \]
\end{definition}

\begin{remark}[Bernoulli random variable]
  A \emph{Bernoulli} random variable is a special case of a binomial random variable with $n = 1$.
\end{remark}

When $n = 1$, we can easily compute that $\Exp[X] = p$ and $\Var(X) = p(1 - p)$.
By the additivity of expectation and variance, it is also easy to compute the expectation and variance for general $n$.
\begin{theorem}[Properties of binomial random variables]
  Let $X \sim \Bin(n, p)$.
  Then
  \begin{enumerate}
    \item $\Exp[X] = np$
    \item $\Var(X) = np(1 - p)$
    \item $\Exp[X^k] = np \Exp[(Y + 1)^{k - 1}]$ where $Y \sim \Bin(n - 1, p)$
  \end{enumerate}
\end{theorem}

\begin{proof}
  A proof of $\Exp[X^k]$ is done with some algebraic manipulation of the definition of $\Exp[X^k]$ and using the identity
  \[
    i \binom{n}{i} = n \binom{n - 1}{i - 1}
  \]
\end{proof}

The following relationship is useful for computing the distribution function of a binomial random variable.
It can also be used to find the maximum of the probability mass function.

\begin{proposition}[Relationship between $\Pr(X = k + 1)$ and $\Pr(X = k)$]
  Let $X \sim \Bin(n, p)$. Then
  \[
    \Pr(X = k + 1) = \frac{p}{1 - p} \frac{n - k}{k + 1} \Pr(X = k).
  \]
\end{proposition}

\begin{corollary}[Condition for monotonic increase]
  Let $X \sim \Bin(n, p)$.
  Then, as $k$ goes from $0$ to $n$, $\Pr(X = k)$ first increases monotonically and then decreases monotonically.
  In fact, $\Pr(X = k) \geq \Pr(X = k + 1)$ if and only if $k \leq (n + 1)p$.
\end{corollary}

\subsection{Poisson random variable}

Besides the binomial random variable, another important discrete random variable is the \emph{Poisson} random variable.

\begin{definition}[Poisson random variable]
  A random variable $X$ is said to be \emph{Poisson} with parameter $\lambda > 0$, denoted by $X \sim \Pois(\lambda)$, if $X$ has the following probability mass function:
  \[
    \Pr(X = i) = e^{-\lambda} \frac{\lambda^i}{i!}, \quad i = 0, 1, 2, \ldots.
  \]
\end{definition}
Observe that the $i$th term is $e^{-\lambda}$ times the $i$th term of the Taylor series expansion of $e^\lambda$.

\begin{remark}
  By the Taylor series expansion of $e^x$, we have
  \[
    \sum_{i = 0}^\infty \Pr(X = i) = e^{-\lambda} \sum_{i = 0}^\infty \frac{\lambda^i}{i!} = e^{-\lambda} e^\lambda = 1.
  \]
\end{remark}

The Poisson random variable is useful for approximating the binomial random variable when $n$ is large and $p$ is small enough so that $\lambda = np$ is of moderate size.

\begin{example}[Examples that can be approximated by a Poisson r.v.]
  We can think of each of these examples as a long series of independent trial, each with a small chance of success.
  Thus, we can approximate the number of successes by a Poisson random variable.
  \begin{enumerate}
    \item The number of misprints on a page of a book.
    \item The number of people in a community who survive to age 100.
    \item The number of wrong telephone numbers dialed in a day.
    \item The number of packages of biscuits sold in a store in a day.
    \item The customers centering a post office on a given day.
  \end{enumerate}
\end{example}

\begin{remark}
  This approximation works decently even with $n$ as small as $10$ and $p$ as large as $0.1$.
  For example, with $X \sim \Bin(10, 0.1)$ and $Y \sim \Pois(1)$, we have
  \[
    \Pr(X \leq 1) \approx 0.7361
  \]
  \[
    \Pr(Y \leq 1) \approx 0.7358
  \]
\end{remark}

\begin{theorem}[Properties of Poisson r.v.]
  Let $X \sim \Pois(\lambda)$.
  Then
  \begin{enumerate}
    \item $\Exp[X] = \lambda$
    \item $\Var(X) = \lambda$
  \end{enumerate}
\end{theorem}
These properties should be intuitive by comparing Poisson random variables with binomial random variables, but with large $n$.

We have shown that the Poisson distribution approximates the binomial distribution when $n$ is large and $p$ is small.
In fact, we do not need the events be independent or to occur with equal probability.
We just need the probability of the events to be small and the events to be at most weakly dependent.
This is explained in what we call the \emph{Poisson paradigm}.

\begin{definition}[Weak dependence]
  Events $E$ and $F$ are weakly dependent if $\Pr(E) \approx \Pr(E \mid F)$.
\end{definition}

\begin{theorem}[Poisson Paradigm]
  Consider $n$ events where the $i$th event occurs with probability $p_i$.
  If all the $p_i$ are small and the trials are either independent or at most weakly dependent, then the number of events that occur approximately has a Poisson distribution with mean $\lambda = \sum_{i = 1}^n p_i$.
\end{theorem}

\begin{proposition}[Relationship between $\Pr(X = k + 1)$ and $\Pr(X = k)$]
  Let $X \sim \Pois(\lambda)$.
  Then
  \[
    \Pr(X = k + 1) = \frac{\lambda}{k + 1} \Pr(X = k).
  \]
\end{proposition}

One other use of the Poisson distribution is in \emph{poisson processes}.

\begin{theorem}[Poisson process]
  Suppose events occur at random points in time, and let $N(t)$ denote the number of events that occur in an interval of length $t$.
  $N(t)$ is a \emph{Poisson process} having rate $\lambda > 0$ if
  \begin{enumerate}
    \item The process begins at time $0$, that is, $N(0) = 0$.
    \item $\Pr(N(h) = 1) = \lambda h + o(h)$
    \item $\Pr(N(h) \geq 2) = o(h)$
    \item The number of events occurring in disjoint time intervals are independent (otherwise called the independent increment assumption).
    \item The distribution of the number of events occurring in a time interval of length $t$ depends only on the length of the interval and not on its location (otherwise called the stationary increment assumption).
  \end{enumerate}
  $N(t)$ has a Poisson distribution with mean $\lambda t$.
\end{theorem}

\begin{example}[Examples of poisson processes]
  Poisson processes can approximate phonemona like:
  \begin{enumerate}
    \item The number of earthquakes occurring in a fixed time span.
    \item The number of wars per year.
    \item The number of electrons emitted from a heated cathode during a fixed time period.
    \item The number of deaths, in a given period of time, of the policyholders of a life insurance company.
  \end{enumerate}
\end{example}

\subsection{Geometric random variable}

Imagine tossing a coin repeatedly until we get a head.
Let $X$ be the number of tosses required.
Then $X$ is a \emph{geometric} random variable.

\begin{definition}[Geometric random variable]
  A random variable $X$ is said to be \emph{geometric} with parameter $p$ if $X$ has the following probability mass function:
  \[
    \Pr(X = i) = (1 - p)^{i - 1} p, \quad i = 1, 2, \ldots.
  \]
\end{definition}

\begin{remark}
  By the geometric series, we have
  \[
    \sum\limits_{i = 1}^\infty \Pr(X = i) = p \sum\limits_{i = 1}^\infty (1 - p)^{i - 1} = 1
  \]
\end{remark}

\begin{proposition}[Properties of geometric r.v.]
  Let $X$ be a geometric random variable with parameter $p$.
  Then
  \begin{enumerate}
    \item $\Exp[X] = 1/p$
    \item $\Var(X) = (1 - p)/p^2$
  \end{enumerate}
\end{proposition}
The expectation should be unsurprising.
The variance should also be somewhat intuitive since
\begin{enumerate}
  \item When $p$ is small, $X$ is approximately an exponential random variable with $\lambda = p$ and so $\Var(X) \approx 1/p^2$.
  \item When $p$ is large, $\Var(X) \approx 0$.
\end{enumerate}

\begin{remark}
  The exponential distribution is the continuous analogue of the geometric distribution.
\end{remark}

\subsection{Negative binomial random variable}

Suppose we toss a coin repeatedly until we get $r$ heads.
Let $X$ be the number of tosses required.
Then $X$ is a \emph{negative binomial} random variable.

\begin{definition}[Negative binomial random variable]
  A random variable $X$ is said to be \emph{negative binomial} with parameters $r$ and $p$ if $X$ has the following probability mass function:
  \[
    \Pr(X = i) = \binom{i - 1}{r - 1} p^r (1 - p)^{i - r}, \quad i = r, r + 1, \ldots.
  \]
\end{definition}

\begin{remark}
  A geometric random variable is a special case of a negative binomial random variable with $r = 1$.
\end{remark}

The following properties should not be surprising since the negative binomial random variable is a sum of $r$ independent geometric random variables.

\begin{proposition}[Properties of negative binomial r.v.]
  Let $X$ be a negative binomial random variable with parameters $r$ and $p$.
  Then
  \begin{enumerate}
    \item $\Exp[X] = r/p$
    \item $\Var(X) = r(1 - p)/p^2$
  \end{enumerate}
\end{proposition}


\subsection{Hypergeometric random variable}

Suppose we randomly choose $n$ balls from an urn containing $m$ white balls and $N - m$ black balls without replacement.
Let $X$ be the number of white balls chosen.
Then $X$ is a \emph{hypergeometric} random variable.

\begin{definition}[Hypergeometric random variable]
  A random variable $X$ is said to be \emph{hypergeometric} with parameters $n$, $N$, and $m$ if $X$ has the following probability mass function:
  \[
    \Pr(X = i) = \frac{\binom{m}{i} \binom{N - m}{n - i}}{\binom{N}{n}}, \quad i = 0, 1, \ldots, n.
  \]
\end{definition}

\begin{proposition}[Properties of hypergeometric r.v.]
  Let $X$ be a hypergeometric random variable with parameters $n$, $N$, and $m$.
  Let $p = m/N$.
  Then
  \begin{enumerate}
    \item $\Exp[X] = np$
    \item $\Var(X) = np(1 - p) \left(1 - \dfrac{n - 1}{N - 1} \right)$
  \end{enumerate}
\end{proposition}

\section{Continuous random variables}

TODO.

\section{Jointly distributed random variables}

TODO.

\section{References}

\begin{enumerate}
  \item A First Course in Probability (10th edition) by Sheldon Ross
\end{enumerate}

\end{document}
